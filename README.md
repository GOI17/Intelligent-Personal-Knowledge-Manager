# Intelligent Personal Knowledge Manager

A fullâ€‘stack, TypeScriptâ€‘only, testâ€‘driven personal knowledge manager that uses AI to summarise, tag, and suggest connections between notes.  
Built with **Next.js**, **RTKâ€‘Toolkit**, **Supabase**, **IndexedDB**, **OpenAI**, and optional **local transformer** inference.

## ðŸš€ Features

| Feature | Humanâ€‘Centered Benefit | AI Contribution |
|---------|-----------------------|-----------------|
| **Write & edit** | Rich markdown, code blocks, instant preview | â€“ |
| **Autoâ€‘tags** | Faster organization | GPTâ€‘4oâ€‘mini â€œWhat tags fit this note?â€ |
| **Summary sidebar** | Quick review | GPTâ€‘4oâ€‘mini â€œSummarise this note in 3 bullets.â€ |
| **Graph view** | Visual link map | GPTâ€‘4oâ€‘mini â€œWhich other notes could be linked to this?â€ |
| **Q&A chat** | Ask â€œWhat did I learn about X?â€ | GPTâ€‘4oâ€‘mini or local transformer |
| **Offline mode** | Work without internet | Local transformer (t5â€‘small) runs inâ€‘browser |
| **Electron wrapper** | Desktop app | â€“ |
| **Local AI toggle** | Switch between serverâ€‘side and inâ€‘browser inference | â€“ |

## ðŸ› ï¸ Tech Stack

- **Framework**: Next.js 14 (App Router, SSR/ISR)
- **Language**: TypeScript
- **UI**: Tailwind CSS + Radix UI
- **State**: Redux Toolkit + RTK Query
- **Database**: Supabase (PostgreSQL) + IndexedDB (Dexie)
- **AI**: OpenAI (serverâ€‘side) + @xenova/transformers (local)
- **Testing**: Jest, React Testing Library, Cypress, axeâ€‘core
- **CI/CD**: GitHub Actions
- **Deployment**: Vercel (serverless API routes)
- **Desktop**: Electron (electronâ€‘forge)

## ðŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/your-username/your-repo.git
cd your-repo

# Install dependencies
npm install
# or
yarn
# or
pnpm
```

### Environment Variables

Create a `.env.local` file at the root and add:

```dotenv
# Supabase
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key

# OpenAI
OPENAI_API_KEY=your-openai-key
```

> **Tip**: Keep the OpenAI key **serverâ€‘side only** â€“ it is never exposed to the browser.

## ðŸš€ Running the App

```bash
# Development
npm run dev
# or
yarn dev
```

Open [http://localhost:3000](http://localhost:3000) to see the app.

## ðŸ“¦ Building for Production

```bash
npm run build
npm start
```

## ðŸ§ª Testing

```bash
# Unit & integration tests
npm test

# Endâ€‘toâ€‘end tests (Cypress)
npm run cy:open
```

All tests run automatically in the CI pipeline.

## ðŸ“¦ CI / CD

- **GitHub Actions**: lint, test, build, and upload artifacts.
- **Vercel**: Oneâ€‘click deploy button in the README (see below).

## ðŸ“± Offline & Local AI

- **IndexedDB**: All notes, tags, and links are cached locally for offline editing.
- **Local Transformer**: Toggle â€œUse local AIâ€ to run summarisation/tagâ€‘suggestion inâ€‘browser (no network).

## ðŸ“¦ Electron Build

```bash
npm run build:electron
```

This produces a native desktop app for Windows, macOS, and Linux.

## ðŸ“„ Documentation

- Architecture diagram (see `docs/architecture.svg`)
- API reference (autoâ€‘generated by Vercel)
- Contribution guide (`CONTRIBUTING.md`)

## ðŸ“¦ Deploy on Vercel

[![Deploy on Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=YOUR_GIT_URL)

Vercel automatically builds the Next.js app and exposes the serverless API routes.

## ðŸ“š FAQ

| Question | Answer |
|----------|--------|
| Can I replace Supabase with Firestore? | Yes â€“ swap the client in the API routes and adjust schemas. |
| What if I need GPTâ€‘4 instead of GPTâ€‘4oâ€‘mini? | Change the model in `pages/api/ai/summarise.ts` to `gpt-4`. |
| Is the local model stable? | @xenova/transformers works on Chrome/Edge/Firefox; Safari is slower. |
| How to handle >â€¯5â€¯k tokens? | Chunk the content, summarise each chunk, concat results, show progress. |
| Do I need a dedicated server? | Vercelâ€™s serverless API routes run on edge nodes; no VM needed. |

## ðŸ“œ License

MIT Â© 2025 Your Name

